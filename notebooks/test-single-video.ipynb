{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfeb927e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/loqui-refactor\n",
      "Already on 'test-model-single-video'\n",
      "Your branch is up to date with 'origin/test-model-single-video'.\n",
      "remote: Enumerating objects: 3, done.\u001B[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001B[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001B[K\n",
      "remote: Total 3 (delta 1), reused 3 (delta 1), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (3/3), 1.14 KiB | 1.14 MiB/s, done.\n",
      "From https://github.com/aviadshimoni/learn-an-effective-lip-reading-model-without-pains\n",
      " * branch            test-model-single-video -> FETCH_HEAD\n",
      "   cb0535b..402660b  test-model-single-video -> origin/test-model-single-video\n",
      "Updating cb0535b..402660b\n",
      "Fast-forward\n",
      " label_sorted.txt       | 242 \u001B[32m++++++++++++++++++++++++++++++++++++++++++++++++\u001B[m\u001B[31m-\u001B[m\n",
      " scripts/prepare_lrw.py |   2 \u001B[32m+\u001B[m\u001B[31m-\u001B[m\n",
      " 2 files changed, 242 insertions(+), 2 deletions(-)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (4.7.0.72)\n",
      "Requirement already satisfied: PyTurboJPEG in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: matplotlib~=3.7.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (10.2.10.91)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (11.7.101)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->-r requirements.txt (line 1)) (10.9.0.58)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.0->-r requirements.txt (line 1)) (67.6.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.0->-r requirements.txt (line 1)) (0.40.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 1)) (16.0.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 1)) (3.26.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (4.39.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (5.12.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib~=3.7.1->-r requirements.txt (line 5)) (1.0.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib~=3.7.1->-r requirements.txt (line 5)) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib~=3.7.1->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.3.0->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.3.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%cd loqui\n",
    "! git checkout main\n",
    "! git pull origin main\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42aa6153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch >= 1.3.0\n",
      "numpy >= 1.16.4\n",
      "opencv-python >= 4.1.0\n",
      "PyTurboJPEG\n",
      "matplotlib~=3.7.1Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.39.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43c4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frames(frames):\n",
    "    # Convert frames to numpy arrays\n",
    "    frames = [np.array(frame, dtype=np.uint8) for frame in frames]\n",
    "\n",
    "    # Resize the frames\n",
    "    resized_frames = [cv2.resize(frame, input_shape) for frame in frames]\n",
    "\n",
    "    # Convert frames to grayscale\n",
    "    grayscale_frames = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in resized_frames]\n",
    "\n",
    "    # Normalize the frames\n",
    "    normalized_frames = [(frame / 255.0).astype(np.float32) for frame in grayscale_frames]\n",
    "\n",
    "    # Stack frames to create a tensor with shape [num_frames, height, width]\n",
    "    tensor_frames = np.stack(normalized_frames)\n",
    "\n",
    "    # Add a channel dimension to the tensor\n",
    "    tensor_frames = np.expand_dims(tensor_frames, axis=1)\n",
    "\n",
    "    # Convert frames to tensor\n",
    "    tensor_frames = torch.tensor(tensor_frames)\n",
    "\n",
    "    return tensor_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f43cb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jpeg = TurboJPEG()\n",
    "\n",
    "def extract_opencv(file_name: str) -> list:\n",
    "    \"\"\"\n",
    "    Gets a path to a video file and tries to extract the ROI from it.\n",
    "    :param file_name: Path to the video file.\n",
    "    :return: ROI of the given video file.\n",
    "    \"\"\"\n",
    "\n",
    "    video = []\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()  # BGR\n",
    "        if ret:\n",
    "            roi = frame[115:211, 79:175]\n",
    "            video.append(roi)\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef53b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frames(frames_to_plot):\n",
    "    num_frames = frames_to_plot.shape[0]\n",
    "    for i in range(num_frames):\n",
    "        frame = numpy_frames[i]  # Extract the frame\n",
    "        if frame.ndim == 3:  # If the frame is 3D, reshape it to 2D\n",
    "            frame = frame.squeeze()\n",
    "        plt.imshow(frame, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9193fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bc54e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/learn-an-effective-lip-reading-model-without-pains\n",
      "From https://github.com/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains\n",
      " * branch            master     -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "%cd learn-an-effective-lip-reading-model-without-pains\n",
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f042bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_missing(model, pretrained_dict):\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict.keys() and v.size() == model_dict[k].size()}                \n",
    "    missed_params = [k for k, v in model_dict.items() if not k in pretrained_dict.keys()]\n",
    "    \n",
    "    print('loaded params/tot params:{}/{}'.format(len(pretrained_dict),len(model_dict)))\n",
    "    print('miss matched params:',missed_params)\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b5070d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args_to_send():\n",
    "    n_class = 5\n",
    "    se = False\n",
    "    border = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ec32e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSR.py\t   __pycache__\tlabel_sorted.txt\t   main_visual.py  scripts\n",
      "README.md  checkpoints\tlrw_roi_npy_gray_pkl_jpeg  model\t   utils\n",
      "/tf/learn-an-effective-lip-reading-model-without-pains\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "!ls\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98bc765",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VideoModel\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtransforms\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mturbojpeg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TurboJPEG\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from model.model import VideoModel\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the desired input shape for the video model\n",
    "input_shape = (88, 88)  # Adjust the dimensions according to the model's requirements\n",
    "\n",
    "\n",
    "video_model = VideoModel(args_to_send)\n",
    "weight = torch.load(\"/tf/loqui/checkpoints/lrw-baseline/_iter_0_epoch_0_v_acc_0.25000_.pt\", map_location=torch.device('cpu'))\n",
    "load_missing(video_model, weight.get('video_model'))\n",
    "video_model.eval()\n",
    "\n",
    "# Replace 'filename.mp4' with the path to your video file\n",
    "filename = '/tf/single-videos/SMALL_00001.mp4'\n",
    "\n",
    "# Get the video frames\n",
    "frames = extract_opencv(filename)\n",
    "\n",
    "# Preprocess the frames\n",
    "frames = preprocess_frames(frames)\n",
    "\n",
    "# Access the preprocessed frames tensor\n",
    "tensor_frames = frames.squeeze(0)\n",
    "\n",
    "# Convert the tensor frames to numpy array\n",
    "numpy_frames = tensor_frames.numpy()\n",
    "\n",
    "plot_frames(numpy_frames)\n",
    "\n",
    "\n",
    "# Pass the frames through the model\n",
    "with torch.no_grad():\n",
    "    frames = frames.unsqueeze(0)\n",
    "    predictions = video_model(frames)\n",
    "    print(f\"predictions: {predictions}\")\n",
    "# Get the predicted label\n",
    "predicted_label = torch.argmax(predictions)\n",
    "print(predicted_label)\n",
    "\n",
    "predicted_label = predicted_label.item()\n",
    "\n",
    "# Print the predicted label\n",
    "print(f'Predicted label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1000, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
